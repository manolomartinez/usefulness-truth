% Fitness Drives Representations to Reality

\begin{abstract}Donald Hoffman's \emph{interface theory of perception} is an
attempt to construct an evolutionary game-theoretic argument for the thesis
that evolution will favor fitness over truth. With the help of models entirely
analogous to those deployed by Hoffman and colleagues, I show that their
argument only supports its skeptical conclusion in the context of extremely
simple cognitive systems, situated in extremely simple environments. As soon as
environments become informationally translucent (in a sense to be explained)
and, as a result, perception starts decoupling from action, truth-tracking
perceptual strategies become the ones with highest expected utility. Hoffman's
"case against reality", having overlooked the way translucency boosts realist
strategies, remains unconvincing.

\end{abstract}

# Introduction

It is unclear in just which way the fitness of agents is related to their
ability to track truths about their environment. Being sensitive to the way the
world is, on the one hand, seems instrumental in negotiating environmental
complexity. On the other hand, it has often been argued that the relation
between fitness and truth is less straightforward than this: sometimes false
beliefs turn out to be adaptive [@mckay_evolution_2009]; sometimes avoiding
misses (false positives) is more important that securing hits
[@godfrey-smith_signal_1991]. When these things happen, it is posslble for
evolution to favor mechanisms which, while perfectly attuned to fitness, have
very imperfect truth-tracking capabilities.

Donald D. Hoffman and colleagues's *interface theory of perception*
[@hoffman_user-interface_2009; @hoffman_computational_2012;
@hoffman_objects_2014; @hoffman_interface_2015; @hoffman_interface_2016;
@mark_evolutionary_2013] is an attempt to move this discussion to a more
formally conspicuous ground, and, while at it, to argue for the radical thesis
that, in general, evolution will favor fitness over truth.  The interface
theory of perception has lately attracted a great deal of interest; academic
as well as popular: Hoffman's ideas have been taken up by outlets such as
*Scientific American* ("Did Humans Evolve to See Things as They Really Are?",
Michael Shermer, November 2015), or *The Atlantic* ("The Case Against Reality",
Amanda Gefter, April 2016.) I will argue here that Hoffman's "case against
reality" is not very strong. My strategy will be to set up the same kind of
models on which Hoffman and colleagues base their skeptical conclusions and
show that, once we start moving away from the very extreme of cognitive and
environmental simplicity, truth-tracking perception quickly becomes fitness
maximizing.

In section 2 I reconstruct Hoffman and colleagues's main model, and the
skeptical argument that depends on it, as presented in
@hoffman_user-interface_2009 and @hoffman_interface_2015. In the model,
*perceptual strategies* have to be construed that take values of a certain cue
(say, the color of a fruit, or the amount of water in a puddle) to one of a
discrete set of *perceptual states*. Perceivers will then use their perceptual
state to choose one among a number of alternative resources. Hoffman and
colleagues show that the perceptual strategy that maximizes the expected
utility of the resources thus obtained is one that gives rise to perceptual
states that are highy informative about the utility of resources, but do not
preserve the structure of the space of possible cues (in a sense to be
explained below)---states that offer, that is, little to no access to those
agent-independent cues.

This argument relies on the following idealization: there is a mathematical
function that takes resource quantities to sensory states, and another function
taking those same resource quantities to utilities. That is, the assumption is
made that *the calculation of a perceptual strategy can take into account all
fitness-relevant facts*. As a result, agents in the model end up needing only
one available action per perceptual state---they are wholly *cue-driven*, in
Sterelny's [-@sterelny_thought_2003] sense.

But the situation faced by perceivers in ecologically realistic contexts is
seldom this favorable: much more often, perceptual strategies for different
sensory modalities need to evolve using as input cues that are only partially
informative about utility---using, that is, cues such that there is *no single
function* taking them to utilities. Utility-maximizing action standards have to
be calculated, subseequently, by putting together the pieces of information
provided by the different sensory modalities---action becoming, thus,
*decoupled* from any single perceptual state. In section 3 I describe a model
(inspired by the decision problem faced by certain species of bark beetle)
fully analogous to Hoffman's model, but such that agents have *two* relevant
responses to perceptions, each one best in a different context. In this model,
the perceptual strategy that maximizes utility is very informative about
agent-independent cues. This is so, intuitively, because perception does not
know which action will maximize utility in the current context, and is thus
forced to "tell it like it is", and leave matters to the discretion of an
action-producing mechanism downstream.

In summary, Hoffman's argument only works for extremely simple cognitive
systems in informationally transparent ecological contexts. Typically, though,
ecologically realistic contexts are informationally translucent. As a result,
perception is typically decoupled from action, and utility-maximizing
perceptual strategies typically track truth.

# The Model

Hoffman and colleagues describe a model in which realist and non-realist
perceptual strategies can be pit against one another. In the model, perceivers
aim at maximizing the utility of the resources they consume, by relying on a
perceptual cue that bear a (possibly non-linear) functional relation to
utility. Think of a banana: the cue that perceivers detect is, say, its color,
which we might encode as a real number from 0 (awfully green) to 1 (nice and
yellow); and its utility be directly linked to its nutritional value in a way
codifiable also as a real from 0 (not very nutritious at all) to 1 (very
nutritious). For these idealized bananas, the function taking cue to utility
will be perhaps monotonically increasing, with higher detectable values (i.e.,
yellower bananas) corresponding to higher utilities (more nutritious ones).

In general, we can model any one such resource as an ordered pair, $\langle d,
u\rangle$. Here, $d$ is the value of a certain perceptual cue; in what follows,
I will talk of *detectable values* to refer to values of the cue, and use $D$
to refer to the set of possible detectable values---in this paper $D$ will
always be the set of reals between 0 and 1. The second member of the resource
pair, $u$, is a utility; the set $U$ of possible utilities will also be the
reals between 0 and
1. There is a *resource function*, $r:D\rightarrow U$, that takes detectable
   values to utilities.  

Perceivers in Hoffman's model can be in a discrete set of perceptual states.
Perhaps, say, they can see red, green, yellow and blue, and when the detectable
value of the resource they are looking at is between 0 and 1/4 they see it as
red, when it's greater than 1/4 and smaller than 1/2 they see it as yellow,
when it's between 1/2 and 3/4 they see it as green, otherwise they see it as
blue (see figure 1). In general, we can use $s$ to refer to individual
perceptual states, and $S$ to refer to the (discrete) set of possible
perceptual states. A *perceptual strategy* is a function, $p:D\rightarrow S$,
that takes detectable values to perceptual states.

Hoffman and colleagues identify *realist* perceptual strategies with those that
preserve world structure, in the sense that there is a *perceptual ranking*
among perceptual states (say, $Blue > Green > Yellow > Red$, for $S = \{Red,
Yellow, Green, Blue\}$.) such that if a detectable value $d_1$ is mapped onto a
perceptual state $s_1$, and another detectable value $d_2$ is mapped onto
another perceptual state $s_2$, then $s_1
> s_2$ entails $d_1 > d_2$. 

What this amounts to can be best seen with an example. Figure 1 shows a realist
strategy, with perceptual states preserving the structure of detectable values
in the sense explained above: e.g., any detectable value falling under $Blue$
is guaranteed to be higher than any detectable value falling under $Green$. On
the other hand, Figure 2 is not a realist strategy: there is no way to define a
lineal ordering of perceptual states that preserves structure, as both very low
and very high detectable values are mapped onto $Red$. I will follow Hoffman
and colleagues in calling such non-structure-preserving strategies *interface
strategies*.^[Hoffman and colleagues offer a general taxonomy of perceptual
strategies in [@hoffman_interface_2015]. The foregoing explication reconstructs
the subset of that taxonomy that is sufficient for our current purposes.]


![A realist strategy](mathematica/realiststrat.pdf){width=50%}

![An interface strategy](mathematica/interfacestrat.pdf){width=50%} 

## A Decision Problem

In a world so characterized, we can present perceivers with a decision problem.
Suppose a perceiver is faced with three resources (each of them, remember,
modeled as a pair of a detectable value and a utility). As above, there are
four available perceptual states, conventionally coded as colors: $S = \{Red,
Yellow, Green, Blue\}$. The perceiver sees the three resources, and chooses one
of them relying on their own perceptual state, by observing the following
*Simple* action standard: 

Simple: 

:   Choose the resource corresponding to the highest perceptual state according
to the perceptual ranking $Blue > Green > Yellow > Red$. In case of draw,
choose randomly.

So, for example, if the three resources are mapped by the perceiver's
perceptual strategy onto \<*Blue*, *Red*, *Blue*\>, the Simple action standard
mandates that the perceiver choose randomly between the first and third
resources. 

Finally, we need a resource function, $r$, connecting detectable values to
utilities. Suppose, to begin with, that the resource function is the identity
function: $r(d) = d$. That is, a resource with a detectable value of $d$ yields
a utility of $d$. It turns out that, in this case, the optimal perceptual
strategy is given by Figure 3.[^figures] This optimal perceptual strategy is a
realist one: detectable values corresponding to a perceptual state $p_1$ are
guaranteed to be higher than any detectable value corresponding to a perceptual
state $p_2$ such that $p_1 > p_2$. So far so good for the realist.


[^figures]:In this figure, and all other analogous ones in the paper, the resource
function is superimposed in translucent white, and the expected utility of the
perceptual strategy is given in a box in the left half of the chart. 

    It should be noted that optimal strategies, here and throughout the paper,
    are calculated by numerical maximization of the relevant expected utility
    equations. It is always possible for the numerical solver to get stuck into
    a local, rather than global, maximum. The code I have used to calculate
    expected utilities and generate the figures in this paper can be downloaded
    from [link redacted for review].

![Optimal perceptual strategy when utility is given by the identity
function.](mathematica/linear_cr.pdf){width=50%}

Now, the catch: the realist perceptual strategy in Figure 3 is optimal only
because the resource function $r$ is monotonically increasing, but there is no
reason to think that, in general, detectable values and utilities should bear
this kind of relation. Consider a slightly more realistic banana example: the
cue goes from green to yellow to black, and the resource function is something
of a Gaussian, high at some intermediate, yellow detectable value, and low at
the green and black extremes. As @hoffman_interface_2015 point out, many
resources have a resource function of this sort. 

![Best realist perceptual strategy for Gaussian
utilities](mathematica/gaussian_cr.pdf){width=50%}

![Optimal perceptual strategy for Gaussian
utilities](mathematica/gaussian_if.pdf){width=50%}

Figure 4 shows the best *realist* perceptual strategy when the resource
function is a Gaussian probability density disttibution, with mean $\mu=0.5$
and standard deviation $\sigma=0.15$, normalized so that all utilities lie
between 0 and 1. This realist strategy is plainly not very good: as perceptual
states are coerced to preserve the structure of detectable values, the most
highly-ranked perceptual state (i.e., the $Blue$ range) must be used to map the
maximum of the resource function, *plus everything to its right*. This means
that a perceiver following this strategy will foolishly choose a resource with
a detectable value of 1 (and zero utility) over one with a detectable value of,
say, 0.3 (and utility of 0.41.) 

Figure 5 gives the optimal perceptual strategy. It maps a narrow range of
detectable values around the maximum of the utility function to $Blue$, and
then pairs of regions symmetrically placed around the maximum for the rest of
perceptual states. This is an interface strategy in Hoffman and colleagues'
sense: seeing, e. g. a $Blue$ resource and a $Green$ resource tells us nothing
about which of the two underlying detectable values is higher. On the other
hand, those perceptual states tell us a great deal about the associated
utilities, and, in particular, that we should pick $Blue$. We may now note
that, in general, non-monotonic resource functions will often correspond to
optimal perceptual strategies that are of the interface kind: it will often pay
to follow the contours of local maxima and minima of utility when mapping
detectable values to perceptual states. This is, in a nutshell, the result that
Hoffman and colleagues allude to when they claim that "[v]eridical perception
escapes extinction only if fitness varies monotonically with truth"
[@hoffman_interface_2015, p. 1480].^[While in this paper I focus on the
expected utility achieved by the different perceptual strategies, Hoffman and
colleagues make their argument in terms of an evolutionary game played between
interface and realist perceivers. In fact, while in general strategies with the
best expected utility need not be evolutionarlily stable, in the games
discussed by Hoffman and colleagues the dynamics of the resulting game are only
responsive to expected utilities [dominating strategies always evolving to
fixation; see @mark_evolutionary_2013,
p. 512], and the evolutionary game-theoretic spin is, as far as I can see,
theoretically idle.]

More than its extravagantly anti-realist ramifications, I believe, the most
useful theoretical product of the interface theory of perception is this
formulation of a clear model where the truth vs fitness controversy can play
out and be assessed formally, In the sequel I will use a very similar model to
show that, *pace* Hoffman, this formal assessment actually favors the truth
camp. 

The skeptical results I have just reviewed depend crucially on there being a
resource function univocally yielding a utility for every detectable value.
This allows perceivers to rely on what I have called the "Simple action
standard", which univocally yields an action for every perceptual state.
Perceivers in Hoffman's models are, thus, wholly *cue-driven*: detectable
values univocally translate to a perceptual state (through a perceptual
strategy), and perceptual states univocally translate into action (through the
Simple action standard.)

On the other hand, if the relation between detectable values and fitness is
one-to-many, utility-maximizing perceivers need to exercise a modicum of
flexibility of response. In such cases, as we are about to see, realist
perceptual strategies maximize expected utility.

# How to Decouple an Interface

One of the examples Hoffman uses to motivate his views on perception is the
male *Julodimorpha bakewelli*, a jewel beetle, who will happily choose a
certain kind of Australian beer bottle (a "stubby") over a female to (attempt
to) mate with [@gwynne_beetles_1983].^[Gwynne and Rentz were awarded the 2011
Ig Nobel prize in biology "for discovering that a certain kind of beetle mates
with a certain kind of Australian beer bottle."] This is so, presumably,
because "[t]he shiny brown colour of the glass is similar to the shiny
yellow-brown elytra of J. bakewelli" [@gwynne_beetles_1983, p. 80] which in
turn, according to Hoffman, suggests that "[t]he beetles’ perceptions relied
not on veridical information but rather on heuristics that worked in the niche
where they evolved [@hoffman_interface_2015, p. 1481].^[@cohen_perceptual_2015
points out that Hoffman's description of the jewel beetle case is tendentious,
and that the correct theory of the content of the beetle's perceptual states
might conclude that the beetle is, after all, correctly representing the
presence of a shiny brown surface, as opposed to incorrectly representing the
presence of a female. While Cohen might well be right about this, the objection
I will presently develop accepts, for the sake of the argument, Hoffman's
preferred gloss on truthfulness as structure preservation.]

One thing that these jewel beetles have in common with the perceivers in the
model of the foregoing section is that the relevant perceptual state (for the
beetle: a perception as of a shiny brown surface; for perceivers in Hoffman's
model: one of $Blue$, $Green$, $Yellow$ and $Red$), is rigidly followed by one
concrete action (for the beetle: attempting to mate; for perceivers in the
model: the action determined by the Simple action standard.) Kim Sterelny
[-@sterelny_thought_2003 p. 34], calls this kind of response to perception
*narrow-banded*, and distinguishes it from *broad-banded* response, in which
agents have a "large menu of potential responses" to perceived features
(*ibid.*). 

Leaving human perceivers (who clearly have broad-banded-response capabilities
in Sterelny's sense) asíde, response strategies that are more flexible than the
very narrow-banded action standard in Hoffman's model are widespread in nature,
and in all likelihood phylogenetically ancient. For example, for many bark
beetles, the decision to use a certain tree as host for breeding and feeding
depends not just on the tree giving out the right semiochemical cue (the right
odor), but also on the color of its bark [@campbell_integration_2006;
@campbell_additive_2009], suggesting that these beetles follow an action
standard of the following sort: "if the relevant semiochemical is present, then
use tree as host if dark-barked, otherwise pass". Hawkmoths  seem to follow an
analogous foraging strategy: they will only pollinate a flower that gives out
the right odor if it also presents the right visual features
[@goyret_effect_2007; @raguso_synergy_2005].^[See @christensen_decoupled_2010
for a compelling discussion of many more cases of broad-band responses in
phylogenetically ancient, simple organisms.] 

Bark beetles and hawkmoths have developed such minimally broad-banded
responses, presumably, because their ecological niche is not as accommodating
as Hoffman's model: semiochemical cues provides incomplete information about
the suitability of a tree as host; bark color provides incomplete, but
complementary, information about the same question, and the bark beetle has had
to evolve a branching decision rule to cope with this situation. The "band" in
these responses is not much broader than the one that gave us beer-loving
beetles, but, as we are about to see, it is already enough to make realist
perceptual strategies utility-maximizing, in a model otherwise fully analogous
to the one described by Hoffman.

## A Translucent World

One cue bark beetles are sensitive to is the concentration of a certain
semiochemical, acquired through olfaction. Besides, information about the
context (whether the relevant tree is of dark or light bark color) is made
available to them via visual perception. Each cue maps in a one-to-many way to
the fittingness of the tree as a host---to its utility as a resource. Knowing
that the tree is dark-barked is not enough to conclude its fittingness. Same
with knowing that it gives out the right odor. This is an example of what
@sterelny_thought_2003 calls *informationally translucent* environments: those
in which "ecologically relevant features of [the perceivers's] environment ...
map in complex, one to many ways onto the cues [these perceivers] can detect"
(*op. cit*, p. 21). In particular, in this very simple case, detectable values
(odors) map in a one-to-two way to payoffs. 

I will now consider a bark-beetle variant of Hoffman's model as presented in
section 2, in which different contexts make different actions
utility-maximizing. The main departure from the previous model is that the
perceptual problem perceivers face will now be posed in *two* different
contexts: there will be two resource functions taking detectable values to
utilities, one for each context. Both functions will be normalized Gaussians
like the one in Hoffman's model. The first one, $r_{left}$, will peak at
$\mu=0.2$ and have a standard deviation of $\sigma=0.15$. This function will be
operative in what I will call the *left context*. The second one, $r_{right}$,
will have the same standard deviation, but peak at $\mu=0.8$, in the *right
context*---see Figure 6. I will also suppose that left and right contexts are
equiprobable, and that the perceiver knows which context it is in at any given
time via a different sensory modality. The intuitive picture is one in which
agents, just like hawkmoths or bark beetles, perceive (say, smell) the
resources before them; and independently know (via a different sensory
modality) whether the world is currently *left* or *right*.

![Two context-dependent resource
functions](mathematica/decoupled_payoffs.pdf){width=75%}

Interface strategies do not maximize expected utility in this model---they are
too smart for their own good. First, trying to track the contours of one
utility function at the expense of the other is obviously suboptimal: figure 7
shows a strategy, one of two symmetric ones, in which perception has chosen to
focus on the right context, and neglect the left one. As a result, this
perceptual system will show terrible performance half of the time. The
expected utility of this strategy is 0.39.

![Interface strategy following one resource
function](mathematica/decoup_1max_if.pdf){width=50%}

![Interface strategy following both resource functions at the same
time](mathematica/decoup_2max_if.pdf){width=50%} 

Second, a perceptual strategy that tries to optimize both contexts at the same
time, as in figure 8, is somewhat, but not much, better. The two blue regions
mean that, e.g., if the right context is operative and there is a resource
whose value falls into the left blue range, that resource will be chosen, even
if its utility is almost zero. The expected utility for this strategy is 0.44.

![The optimal perceptual strategy for the translucent
world](mathematica/decoup_both_cr.pdf){width=50%} 

The optimal perceptual strategy, in figure 9, takes into account the fact that
the perceiver knows which context it is in through a different sensory
modality. The perceiver, in its turn, will not make a decision to act solely on
the basis of its perceptual state, but rather combine it with what they know
about the operative context into the following, minimally broad-band action
standard, reminiscent of the decision strategy employed by bark beetles:

Broad-band:

:   When in the left context, choose the resource corresponding to the *lowest*
    perceptual state according to the perceptual ranking $Blue > Green > Yellow
    > Red$. In case of draw, choose randomly. 

    When in the right context, choose the resource corresponding to the
    *highest* perceptual state according to the perceptual ranking $Blue >
    Green > Yellow > Red$. In case of draw, choose randomly. 

In a nutshell, perception is not trying to second-guess the use to which
information about detectable values will be put---it is not trying to follow
the contours of a resource function it only carries partial information about.
It is rather "telling it like it is", so that information about detectable
values can be combined with information about the operative context into the
Broad-band action standard. This is a realist strategy, and it yields an
expected utility of 0.66, 50% higher than the best non-realist strategy. 

This result is not an artifact of the actual resource functions in figure 6.
Figure 10 shows what happens to expected utilities if we move the Gaussian
curves further apart or closer together. When the means of the two curves are
separated more than one standard deviation (0.15), give or take, the realist
strategy wins. Only when the curves mostly overlap (that is, when the world is
not in fact translucent) does a different, interface strategy become optimal.
Hoffman's case against reality, having overlooked the way translucency boosts
realist strategies, remains unconvincing.

![Expected utilities for realists and non-realists, for different arrangements of
resource functions. $\mu$ marks the position of the mean for $r_{left}$. The mean
for $r_{right}$ is placed symmetrically, at $1-\mu$.
](mathematica/expectedpayoffs.pdf){width=75%} 

# References {-}
